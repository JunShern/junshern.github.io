<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chan Jun Shern</title>
  
  <meta name="author" content="Chan Jun Shern">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chan Jun Shern</name>
              </p>
              <p>I'm a researcher working on artificial intelligence safety.
              </p>
              <p>
		Currently working with <a href="https://openai.com/">OpenAI</a> to build evaluations of frontier models, towards enabling clear-eyed governance of high-risk systems.
	        I‚Äôve also spent time doing research at the¬†<a href="https://www.cais.ai/">Center for AI Safety</a>, UC Berkeley's <a href="https://humancompatible.ai/">Center for Human-Compatible AI</a> and¬†<a href="https://wp.nyu.edu/cilvr/">CILVR</a>¬†(New York University).
              </p>
              <p>
                In a previous life, I was a senior research engineer at <a href="https://motional.com/">Motional</a>, where I worked on sensor calibration for autonomous vehicles.
                I did my undergrad at Imperial College London, where I won the <a href="https://www.imperial.ac.uk/electrical-engineering/study/current-students-course-handbook/prizes/">Student Centenary Prize</a> for my undergrad thesis on <a href="https://github.com/JunShern/comper">music generation for musician accompaniment</a>.
              </p>
	      <p>
	        Occasionally open to advising / collaborations. Reach out via email if you'd like to work together! Separately, if you have feedback for me, <a href="https://forms.gle/w9mMJ4Jeq8pzmaeDA">I'd love to hear it</a>.
	      </p>
              <p style="text-align:center">
                <a href="mailto:chanjunshern@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/chanjunshern_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=iUGazLcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/junshernchan">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/JunShern/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/chan-jun-shern/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/ChanJunShern.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ChanJunShern_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in studying how advanced machine learning systems will impact society. My recent work has focused on measuring how large language models behave and figuring out how to robustly keep them in alignment with human values. My favorite papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/machiavelli.png" width="160px">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2304.03279">
                <papertitle>Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark</papertitle>
              </a>
              <br>Alexander Pan*, <strong>Chan Jun Shern*</strong>, Andy Zou*, Nathaniel Li, Steven Basart, Thomas Woodside, Jonathan Ng, Hanlin Zhang, Scott Emmons, Dan Hendrycks
              <br>
              <em>ICML 2023 (oral presentation)</em>
              <br>
                <a href="https://arxiv.org/abs/2304.03279">arXiv</a> / 
                <a href="https://aypan17.github.io/machiavelli/">website</a> /
                <a href="https://twitter.com/DanHendrycks/status/1644371530787467264">tweet</a> / 
                <a href="https://github.com/aypan17/machiavelli">code</a>
              <p></p>
              <p>We develop the Machiavelli benchmark to measure deception, power-seeking tendencies, and other unethical behaviors in complex interactive environments that simulate the real world.</p>
            </td>
          </tr>


          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/emodiversity.png" width="160px">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2210.10039">
                  <papertitle>How Would The Viewer Feel? Estimating Wellbeing From Video Scenarios</papertitle>
                </a>
                <br>Mantas Mazeika, Eric Tang, Andy Zou, Steven Basart, <strong>Jun Shern Chan</strong>, Dawn Song, David Forsyth, Jacob Steinhardt, Dan Hendrycks
                <br>
                <em>NeurIPS 2022</em>
                <br>
                  <a href="https://arxiv.org/abs/2210.10039">arXiv</a> / 
                  <a href="https://github.com/hendrycks/emodiversity">code</a>
                <p></p>
                <p>We introduce two datasets with over 60,000 videos manually annotated for human emotional response, and show how video models can be trained to understand human preferences and the emotional content of videos.</p>
              </td>
          </tr>
    

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/unpredictable.png" width="160px">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2208.01009">
                <papertitle>Few-shot Adaptation Works with UnpredicTable Data</papertitle>
              </a>
              <br><strong>Jun Shern Chan</strong>, Michael Pieler, Jonathan Jao, J√©r√©my Scheurer, Ethan Perez<br>
              <em>ACL Rolling Review 2022, ACL 2023</em>
              <br>
              <a href="https://arxiv.org/abs/2208.01009">arXiv</a> /
							<a href="https://twitter.com/junshernchan/status/1554151844879876096">tweet</a> / 
              <a href="https://github.com/JunShern/few-shot-adaptation">code</a>
              <p></p>
              <p>Training on odd data (e.g. tables from support.google.com) improves few-shot learning with language models in the same way as diverse NLP data.</p>
            </td>
          </tr>

          
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/language_feedback.png" width="160px">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2204.14146/">
                <papertitle>Training Language Models with Language Feedback</papertitle>
              </a>
              <br>J√©r√©my Scheurer, Jon Ander Campos, <strong>Jun Shern Chan</strong>, Angelica Chen, Kyunghyun Cho, Ethan Perez<br>
              <em>ACL 2022 Workshop on Learning with Natural Language Supervision</em>
              <br>
							<a href="https://arxiv.org/abs/2204.14146">arXiv</a> / 
							<a href="https://twitter.com/jeremy_scheurer/status/1521174014194032642">tweet</a> / 
              <a href="https://youtu.be/oEnyl9dMKCc">talk</a>
              <p></p>
              <p>We found a way to learn from language feedback (not ratings), enabling us to finetune GPT3 to human-level summarization quality with just 100 feedback samples.</p>
            </td>
          </tr>


          <tr onmouseout="loss_stop()" onmouseover="loss_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/basalt.png" width="160px">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2204.07123">
                <papertitle>Retrospective on the 2021 BASALT Competition on Learning from Human Feedback</papertitle>
              </a>
              <br>
              Rohin Shah, Steven H. Wang, Cody Wild, Stephanie Milani, Anssi Kanervisto, Vinicius G. Goecks, Nicholas Waytowich, David Watkins-Valls, Bharat Prakash, Edmund Mills, Divyansh Garg, Alexander Fries, Alexandra Souly, <strong>Chan Jun Shern</strong>, Daniel del Castillo, Tom Lieberum
              <br>
              <em>NeurIPS 2021 Competitions and Demonstrations Track</em>
              <br>
              <a href="https://arxiv.org/abs/2204.07123">arxiv</a> /
              <a href="https://minerl.io/basalt/">website</a> /
              <a href="https://www.aicrowd.com/challenges/neurips-2021-minerl-basalt-competition">competition</a> /
              <a href="https://youtu.be/IjNf7Wc3E90">talk</a>
              <p></p>
              <p>The BASALT competition calls for research towards agents that use human feedback to solve open-world tasks in Minecraft. My team combined learning from human demos and preference ratings, earning 3rd place and the "Creativity of research" prize.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Misc projects + writing</heading>
                <p>
                  <ul>
                    <li style="list-style-position:outside;margin:10px 0;padding:0;text-align:left;">2022/09: <a href="https://junshern.notion.site/f01d38f80ba745468aef23284f3f6e37", target="_blank">ML Experiment Workflow</a> 
                      <br>A writeup of helpful workflow tips I've discovered for running ML experiments including code structure, working with compute clusters, experiment tracking, logging, and more.</li>
                      <li style="list-style-position:outside;margin:10px 0;padding:0;text-align:left;">2021/06: <a href="https://www.notion.so/32967c063b9f463b92525246d84540d6", target="_blank">Spinning Up in Deep RL</a> 
                        <br>Blog post detailing my experience implementing key RL algorithms.</li>
                    <li style="list-style-position:outside;margin:10px 0;padding:0;text-align:left;">2021/05: <a href="https://junshern.github.io/paper-reading-group/", target="_blank">Paper Reading Group</a> 
                      <br>I distill AI research publications into 10-slide summaries. (>1k followers)</li>
                    <li style="list-style-position:outside;margin:10px 0;padding:0;text-align:left;">2021/06: <a href="https://www.notion.so/What-is-AI-For-Good-c3bd1c203ca3443b8fdf7d97c397010f", target="_blank">What is AI For Good?</a> 
                      <br>I wrote a layman‚Äôs survey of AI applications for social good. (Probably outdated now)</li>
                    <li style="list-style-position:outside;margin:10px 0;padding:0;text-align:left;">2018/10: <a href="https://junshern.github.io/algorithmic-music-tutorial/", target="_blank">Algorithmic Music Composition</a> 
                      <br>An interactive web tutorial on algorithm music composition, created with <a href="https://github.com/processing/p5.js/">p5.js</a> for <a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a>.</li>
                    <li style="list-style-position:outside;margin:10px 0;padding:0;text-align:left;">2018/08: <a href="https://medium.com/@chanjunshern/free-creative-coding-classes-for-beginners-4a7de5b05f68", target="_blank">Creative Coding Workshop</a> 
                      <br>I developed a (JavaScript) <a href="https://junshern.github.io/creative-coding-workshop/">curriculum</a> and taught beginner coding workshops in Kuala Lumpur. </li>
                  </ul>
                </p>
              </td>
            </tr>
          </tbody>
        </table>
				


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Site adapted from <a href="https://github.com/jonbarron/jonbarron_website">jonbarron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
